<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="/shared/IDEAS-developments/template-columbia/_assets/thirdpartylib/bootstrap-4.3.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="/shared/IDEAS-developments/template-columbia/_assets/thirdpartylib/fontawesome-free-5.9.0-web/css/all.min.css">
    <link rel="stylesheet" href="/shared/IDEAS-developments/template-columbia/_assets/css/styles.min.css">
    <link rel="stylesheet" href="/shared/IDEAS-developments/template-columbia/_assets/css/custom.css">
    <script src="//ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script src="/shared/videos/ableplayer/thirdparty/js.cookie.js"></script>
    <link rel="stylesheet" href="/shared/videos/ableplayer/build/ableplayer.min.css" type="text/css">
    <script src="/shared/videos/ableplayer/build/ableplayer.min.js"></script>
    <script src="https://player.vimeo.com/api/player.js"></script>
    <script src="https://cdnapisec.kaltura.com/p/823192/sp/82319200/embedIframeJs/uiconf_id/46847663/partner_id/823192"></script>
    <script src="/shared/videos/ableplayer/ablefier.js"></script>
    <style>
          h3 { font-style: italic; }
          pre { font-weight: bold; }
    </style>
<title>Module 8 Summary</title>
</head><body><div class="container-fluid">
<div class="row">
<div class="col-12 banner-img"><p><img src="img/banner.jpg" alt="banner"></p></div>
<div class="col-sm-10 offset-sm-1">
<h1>Module 8 Summary</h1>
<h2>Wrap Up</h2>
<p>In this module, we studied memory from the hardware level and then used that knowledge to write faster code. We began with the underlying storage technologies &mdash; SRAM and DRAM &mdash; and saw how the enormous speed gap between the CPU and main memory motivates the entire memory hierarchy. We explored how the principle of locality allows caching to be effective, and how cache organization (direct-mapped, set-associative) determines hit rates and performance. From there, we turned to optimization: when it matters, what the compiler can do automatically, how to measure where time is actually spent, and the code-level techniques a programmer can apply. We concluded with cache-aware programming, where understanding the hardware directly translates into dramatic performance improvements.</p>
<div class="stacked-panels row">
<div class="card bg-light col-12">
<div class="card-body">
<h2>Key Takeaways</h2>
<ul>
<li><b>The memory hierarchy</b> is a series of storage levels (registers, L1/L2/L3 caches, main memory, disk) where each level serves as a cache for the level below. Faster levels are smaller and more expensive per byte; slower levels are larger and cheaper. Locality is what makes this hierarchy effective.</li>
<li><b>Locality</b> comes in two forms: temporal (recently accessed data will likely be accessed again soon) and spatial (data near recently accessed data will likely be accessed soon). Writing code with good locality is one of the most impactful optimizations a programmer can make.</li>
<li><b>Caches</b> exploit locality by storing recently used data in fast SRAM close to the CPU. Cache organization &mdash; including cache lines, sets, mapping schemes, and write policies &mdash; determines how effectively the cache can reduce average memory access time.</li>
<li><b>Correctness comes first.</b> Optimization should only be pursued after a program is working correctly, and only when measurement shows that the performance improvement is meaningful. Not every program needs to be optimized.</li>
<li><b>The compiler is a powerful optimizer.</b> Using gcc's optimization flags (<code>-O1</code>, <code>-O2</code>, <code>-O3</code>) can yield significant speedups automatically. However, the compiler must produce code that behaves identically in all cases, so it cannot make optimizations that depend on assumptions about pointer aliasing or side effects. Writing compiler-friendly code helps the compiler do its job better.</li>
<li><b>Measure before you optimize.</b> Profiling tools like <b>gprof</b> show exactly which functions and loops consume the most time. Always profile first and focus optimization efforts on the hot spots.</li>
<li><b>Code-level techniques</b> include reducing procedure calls in loops, eliminating unnecessary memory references (accumulating in registers instead), loop unrolling, and exploiting instruction-level parallelism.</li>
<li><b>Cache-aware programming</b> is one of the most impactful optimizations. Traversing 2D arrays in row-major order, using loop tiling for matrix computations, and choosing data layouts that match access patterns can yield order-of-magnitude speedups by keeping data in cache.</li>
</ul>
</div>
</div>
</div>
<h2>Additional Resources</h2>
<p><a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=3b0c2f59-9a24-4688-907a-14b2b3183385" target="_blank" rel="noopener">Cache Memories</a> (Video Lecture from Carnegie Mellon University)</p>
<p><a href="https://scs.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=4e223f75-3a04-4547-a283-09bfba57f4b7" target="_blank" rel="noopener">Program Optimization</a> (Video Lecture from Carnegie Mellon University)</p>
<footer>End of Module 8 Summary</footer></div>
</div>
</div></body></html>
